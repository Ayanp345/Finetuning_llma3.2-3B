# Finetuning_llma3.2-3B
This repository showcases end-to-end supervised fine-tuning of the Llama 3.2B model using Unsloth, Hugging Faceâ€™s Transformers, and TRL libraries

# ðŸ¦™ Finetuning LLaMA 3.2 (3B) â€“ Detailed Walkthrough


## ðŸ“– Project Overview

This repository demonstrates how to **finetune the LLaMA 3.2 (3B)** language model using modern LLM training techniques and libraries (e.g., Unsloth, Hugging Face Transformers).

The project follows the step-by-step instructions in the video, covering:

- Setting up environment & dependencies  
- Preparing and formatting datasets  
- Configuring the model and hyperparameters  
- Running the finetuning loop  
- Evaluating results with metrics & examples  
- Saving and reusing model checkpoints  

